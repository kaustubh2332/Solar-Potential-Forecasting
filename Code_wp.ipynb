{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O65OmuGhKMNy",
        "outputId": "ea97e160-53e5-476e-82a2-28e719f8c11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE SOLAR FORECASTING FRAMEWORK\n",
            "================================================================================\n",
            "\n",
            "STEP 1: DATA LOADING AND PREPROCESSING\n",
            "Loading and preprocessing solar irradiance data...\n",
            "Creating comprehensive temporal features...\n",
            "Dataset shape: (8760, 44)\n",
            "Date range: 2019-01-01 00:00:00 to 2019-12-31 23:00:00\n",
            "Total duration: 364 days\n",
            "Years covered: [np.int32(2019)]\n",
            "Mean solar irradiance: 172.66 W/m²\n",
            "Max solar irradiance: 1003.02 W/m²\n",
            "============================================================\n",
            "\n",
            "STEP 2: COMPREHENSIVE MODEL COMPARISON\n",
            "\n",
            "============================================================\n",
            "COMPREHENSIVE MODEL COMPARISON\n",
            "============================================================\n",
            "Preparing features for modeling...\n",
            "Added weather features: ['cloud_cover', 'relative_humidity', 'wind_speed', 'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
            "Total features: 31\n",
            "Training: 5256 | Validation: 1752 | Test: 1752\n",
            "\n",
            "Training RANDOM_FOREST model...\n",
            "\n",
            "Training XGBOOST model...\n",
            "\n",
            "Training SVM model...\n",
            "\n",
            "Training GRADIENT_BOOSTING model...\n",
            "\n",
            "Training NEURAL_NETWORK model...\n",
            "================================================================================\n",
            "COMPREHENSIVE MODEL COMPARISON REPORT\n",
            "================================================================================\n",
            "Analysis Date: 2025-06-08 07:30:11\n",
            "\n",
            "PERFORMANCE RANKING\n",
            "----------------------------------------\n",
            "Best R² Score: random_forest (0.9183)\n",
            "Best RMSE: random_forest (41.3706)\n",
            "\n",
            "DETAILED COMPARISON\n",
            "----------------------------------------\n",
            "RANDOM_FOREST:\n",
            "  RMSE: 41.3706\n",
            "  R²: 0.9183\n",
            "  MAE: 23.6375\n",
            "  Training Time: 3014.97s\n",
            "\n",
            "XGBOOST:\n",
            "  RMSE: 51.6480\n",
            "  R²: 0.8726\n",
            "  MAE: 33.2590\n",
            "  Training Time: 1.29s\n",
            "\n",
            "SVM:\n",
            "  RMSE: 93.7244\n",
            "  R²: 0.5806\n",
            "  MAE: 87.3776\n",
            "  Training Time: 5.62s\n",
            "\n",
            "GRADIENT_BOOSTING:\n",
            "  RMSE: 43.1664\n",
            "  R²: 0.9110\n",
            "  MAE: 26.2949\n",
            "  Training Time: 12.18s\n",
            "\n",
            "NEURAL_NETWORK:\n",
            "  RMSE: 92.4189\n",
            "  R²: 0.5922\n",
            "  MAE: 69.4978\n",
            "  Training Time: 11.98s\n",
            "\n",
            "\n",
            "STEP 4: TEMPORAL RESOLUTION ANALYSIS\n",
            "Analyzing 30min resolution...\n",
            "Preparing features for modeling...\n",
            "Added weather features: ['cloud_cover', 'relative_humidity', 'wind_speed', 'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
            "Total features: 31\n",
            "Training: 10513 | Validation: 3503 | Test: 3503\n",
            "Analyzing hourly resolution...\n",
            "Preparing features for modeling...\n",
            "Added weather features: ['cloud_cover', 'relative_humidity', 'wind_speed', 'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
            "Total features: 31\n",
            "Training: 5256 | Validation: 1752 | Test: 1752\n",
            "Analyzing daily resolution...\n",
            "Preparing features for modeling...\n",
            "Added weather features: ['cloud_cover', 'relative_humidity', 'wind_speed', 'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
            "Total features: 31\n",
            "Training: 219 | Validation: 73 | Test: 73\n",
            "Analyzing weekly resolution...\n",
            "Preparing features for modeling...\n",
            "Added weather features: ['cloud_cover', 'relative_humidity', 'wind_speed', 'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
            "Total features: 31\n",
            "Training: 33 | Validation: 10 | Test: 10\n",
            "\n",
            "STEP 6: COMPREHENSIVE REPORT GENERATION\n",
            "\n",
            "Generating comprehensive framework report...\n",
            "COMPREHENSIVE SOLAR FORECASTING FRAMEWORK REPORT\n",
            "================================================================================\n",
            "Generated: 2025-06-08 10:12:03\n",
            "\n",
            "================================================================================\n",
            "FRAMEWORK ANALYSIS COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n",
            "Results saved in 'solar_analysis_results/' directory\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('solar_analysis_results', exist_ok=True)\n",
        "os.makedirs('solar_analysis_results/plots', exist_ok=True)\n",
        "os.makedirs('solar_analysis_results/models', exist_ok=True)\n",
        "os.makedirs('solar_analysis_results/comparisons', exist_ok=True)\n",
        "\n",
        "class ComprehensiveSolarForecaster:\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.df = None\n",
        "        self.models = {}\n",
        "        self.features = None\n",
        "        self.target = None\n",
        "        self.scaler = None\n",
        "        self.best_params = {}\n",
        "        self.weather_features = ['cloud_cover', 'relative_humidity', 'wind_speed',\n",
        "                               'air_pressure', 'visibility', 'precipitation', 'temperature']\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "        \"\"\"Load and preprocess solar irradiance data with enhanced features\"\"\"\n",
        "        print(\"Loading and preprocessing solar irradiance data...\")\n",
        "\n",
        "        self.df = pd.read_csv(self.data_path)\n",
        "\n",
        "        # Create datetime column\n",
        "        self.df['datetime'] = pd.to_datetime({\n",
        "            'year': self.df['YEAR'],\n",
        "            'month': self.df['MO'],\n",
        "            'day': self.df['DY'],\n",
        "            'hour': self.df['HR']\n",
        "        })\n",
        "\n",
        "        self.df = self.df.sort_values('datetime').reset_index(drop=True)\n",
        "        self._create_comprehensive_features()\n",
        "        self._display_dataset_info()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def _create_comprehensive_features(self):\n",
        "        \"\"\"Create comprehensive temporal and cyclical features\"\"\"\n",
        "        print(\"Creating comprehensive temporal features...\")\n",
        "\n",
        "        # Basic temporal features\n",
        "        self.df['hour'] = self.df['datetime'].dt.hour\n",
        "        self.df['day'] = self.df['datetime'].dt.day\n",
        "        self.df['day_of_week'] = self.df['datetime'].dt.dayofweek\n",
        "        self.df['month'] = self.df['datetime'].dt.month\n",
        "        self.df['year'] = self.df['datetime'].dt.year\n",
        "        self.df['day_of_year'] = self.df['datetime'].dt.dayofyear\n",
        "\n",
        "        # Cyclical encoding\n",
        "        self.df['hour_sin'] = np.sin(2 * np.pi * self.df['hour']/24)\n",
        "        self.df['hour_cos'] = np.cos(2 * np.pi * self.df['hour']/24)\n",
        "        self.df['month_sin'] = np.sin(2 * np.pi * self.df['month']/12)\n",
        "        self.df['month_cos'] = np.cos(2 * np.pi * self.df['month']/12)\n",
        "        self.df['day_of_year_sin'] = np.sin(2 * np.pi * self.df['day_of_year']/365)\n",
        "        self.df['day_of_year_cos'] = np.cos(2 * np.pi * self.df['day_of_year']/365)\n",
        "        self.df['day_of_week_sin'] = np.sin(2 * np.pi * self.df['day_of_week']/7)\n",
        "        self.df['day_of_week_cos'] = np.cos(2 * np.pi * self.df['day_of_week']/7)\n",
        "\n",
        "        # Season features (as numeric to avoid categorical interpolation issues)\n",
        "        self.df['season_numeric'] = ((self.df['month'] % 12) // 3)  # 0=Winter, 1=Spring, 2=Summer, 3=Fall\n",
        "\n",
        "        # Create season dummies directly\n",
        "        self.df['is_spring'] = (self.df['month'].isin([3, 4, 5])).astype(int)\n",
        "        self.df['is_summer'] = (self.df['month'].isin([6, 7, 8])).astype(int)\n",
        "        self.df['is_fall'] = (self.df['month'].isin([9, 10, 11])).astype(int)\n",
        "        # Winter is the baseline (when all other seasons are 0)\n",
        "\n",
        "        # Binary indicators\n",
        "        self.df['is_weekend'] = self.df['day_of_week'].isin([5, 6]).astype(int)\n",
        "        self.df['is_winter'] = self.df['month'].isin([12, 1, 2]).astype(int)\n",
        "\n",
        "        # Lag features\n",
        "        self.df['prev_hour_irradiance'] = self.df['ALLSKY_SFC_SW_DWN'].shift(1)\n",
        "        self.df['prev_day_irradiance'] = self.df['ALLSKY_SFC_SW_DWN'].shift(24)\n",
        "        self.df['prev_week_irradiance'] = self.df['ALLSKY_SFC_SW_DWN'].shift(24*7)\n",
        "\n",
        "        # Rolling features\n",
        "        self.df['24h_rolling_avg'] = self.df['ALLSKY_SFC_SW_DWN'].rolling(window=24, center=True).mean()\n",
        "        self.df['7d_rolling_avg'] = self.df['ALLSKY_SFC_SW_DWN'].rolling(window=24*7, center=True).mean()\n",
        "\n",
        "        # Fill NaN values\n",
        "        self.df = self.df.fillna(method='bfill')\n",
        "        self.df = self.df.fillna(method='ffill')\n",
        "\n",
        "    def _display_dataset_info(self):\n",
        "        print(f\"Dataset shape: {self.df.shape}\")\n",
        "        print(f\"Date range: {self.df['datetime'].min()} to {self.df['datetime'].max()}\")\n",
        "        print(f\"Total duration: {(self.df['datetime'].max() - self.df['datetime'].min()).days} days\")\n",
        "        print(f\"Years covered: {sorted(self.df['year'].unique())}\")\n",
        "        print(f\"Mean solar irradiance: {self.df['ALLSKY_SFC_SW_DWN'].mean():.2f} W/m²\")\n",
        "        print(f\"Max solar irradiance: {self.df['ALLSKY_SFC_SW_DWN'].max():.2f} W/m²\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    def prepare_features(self, target='ALLSKY_SFC_SW_DWN', include_weather=True):\n",
        "        \"\"\"Prepare features for modeling\"\"\"\n",
        "        print(\"Preparing features for modeling...\")\n",
        "\n",
        "        base_features = [\n",
        "            'hour', 'day', 'day_of_week', 'month', 'day_of_year',\n",
        "            'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "            'day_of_year_sin', 'day_of_year_cos', 'day_of_week_sin', 'day_of_week_cos',\n",
        "            'is_weekend', 'is_summer', 'is_winter', 'season_numeric',\n",
        "            'is_spring', 'is_fall'\n",
        "        ]\n",
        "\n",
        "        lag_features = ['prev_hour_irradiance', 'prev_day_irradiance',\n",
        "                       'prev_week_irradiance', '24h_rolling_avg', '7d_rolling_avg']\n",
        "\n",
        "        self.features = base_features + lag_features\n",
        "\n",
        "        # Add weather features if available and requested\n",
        "        if include_weather:\n",
        "            available_weather = [f for f in self.weather_features if f in self.df.columns]\n",
        "            self.features.extend(available_weather)\n",
        "            print(f\"Added weather features: {available_weather}\")\n",
        "\n",
        "        self.target = target\n",
        "        print(f\"Total features: {len(self.features)}\")\n",
        "        return self.features, self.target\n",
        "\n",
        "    def split_data_temporal(self, test_size=0.2, validation_size=0.2):\n",
        "        \"\"\"Temporal data splitting for time series\"\"\"\n",
        "        X = self.df[self.features].copy().fillna(0)\n",
        "        y = self.df[self.target].copy()\n",
        "\n",
        "        n_samples = len(X)\n",
        "        n_test = int(n_samples * test_size)\n",
        "        n_val = int(n_samples * validation_size)\n",
        "        n_train = n_samples - n_test - n_val\n",
        "\n",
        "        X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
        "        y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        print(f\"Training: {len(X_train)} | Validation: {len(X_val)} | Test: {len(X_test)}\")\n",
        "        return X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\n",
        "\n",
        "    def compare_models(self, models_to_compare=None):\n",
        "        \"\"\"Compare multiple ML models comprehensively\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if models_to_compare is None:\n",
        "            models_to_compare = ['random_forest', 'xgboost', 'svm', 'gradient_boosting', 'neural_network']\n",
        "\n",
        "        # Prepare data\n",
        "        self.prepare_features()\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data_temporal()\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for model_name in models_to_compare:\n",
        "            print(f\"\\nTraining {model_name.upper()} model...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            if model_name == 'random_forest':\n",
        "                model = self._build_random_forest(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            elif model_name == 'xgboost':\n",
        "                model = self._build_xgboost(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            elif model_name == 'svm':\n",
        "                model = self._build_svm(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            elif model_name == 'gradient_boosting':\n",
        "                model = self._build_gradient_boosting(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            elif model_name == 'neural_network':\n",
        "                model = self._build_neural_network(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "            metrics = self.models[model_name]['metrics']\n",
        "            metrics['training_time'] = training_time\n",
        "\n",
        "            results.append({\n",
        "                'model': model_name,\n",
        "                'train_rmse': metrics['train_rmse'],\n",
        "                'test_rmse': metrics['test_rmse'],\n",
        "                'test_mae': metrics['test_mae'],\n",
        "                'test_r2': metrics['test_r2'],\n",
        "                'training_time': training_time\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        self._plot_model_comparison(results_df)\n",
        "        self._generate_model_comparison_report(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _build_random_forest(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        \"\"\"Build Random Forest model with hyperparameter optimization\"\"\"\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [10, 20, 30, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "\n",
        "        rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "        grid_search = GridSearchCV(rf, param_grid, cv=tscv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        self.best_params['random_forest'] = grid_search.best_params_\n",
        "\n",
        "        # Train and predict\n",
        "        best_model.fit(X_train, y_train)\n",
        "        y_train_pred = best_model.predict(X_train)\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
        "\n",
        "        self.models['random_forest'] = {'model': best_model, 'metrics': metrics}\n",
        "        return best_model\n",
        "\n",
        "    def _build_xgboost(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        try:\n",
        "            from xgboost import XGBRegressor\n",
        "\n",
        "            model = XGBRegressor(\n",
        "                n_estimators=200, learning_rate=0.1, max_depth=6,\n",
        "                subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
        "            )\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
        "            self.models['xgboost'] = {'model': model, 'metrics': metrics}\n",
        "\n",
        "            return model\n",
        "        except ImportError:\n",
        "            print(\"XGBoost not available. Install with: pip install xgboost\")\n",
        "            return None\n",
        "\n",
        "    def _build_svm(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        \"\"\"Build SVM model\"\"\"\n",
        "        model = SVR(kernel='rbf', C=100, epsilon=0.1, gamma='scale')\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
        "        self.models['svm'] = {'model': model, 'metrics': metrics}\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _build_gradient_boosting(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        model = GradientBoostingRegressor(\n",
        "            n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
        "        self.models['gradient_boosting'] = {'model': model, 'metrics': metrics}\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _build_neural_network(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        model = MLPRegressor(\n",
        "            hidden_layer_sizes=(100, 50), activation='relu', solver='adam',\n",
        "            alpha=0.001, batch_size='auto', learning_rate='constant',\n",
        "            learning_rate_init=0.001, max_iter=1000, random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
        "        self.models['neural_network'] = {'model': model, 'metrics': metrics}\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _calculate_metrics(self, y_train, y_train_pred, y_test, y_test_pred):\n",
        "        return {\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_r2': r2_score(y_test, y_test_pred),\n",
        "            'test_mape': np.mean(np.abs((y_test - y_test_pred) / (y_test + 1e-8))) * 100\n",
        "        }\n",
        "\n",
        "    def test_geographic_transferability(self, locations_list, base_model_name='random_forest'):\n",
        "        results = []\n",
        "\n",
        "        # Train base model on first location\n",
        "        base_location = locations_list[0]\n",
        "        print(f\"Training base model on {base_location['name']} data...\")\n",
        "\n",
        "        self.data_path = base_location['data_path']\n",
        "        self.load_and_preprocess()\n",
        "        self.prepare_features()\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data_temporal()\n",
        "\n",
        "        if base_model_name == 'random_forest':\n",
        "            base_model = self._build_random_forest(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "        base_metrics = self.models[base_model_name]['metrics']\n",
        "        results.append({\n",
        "            'location': base_location['name'],\n",
        "            'lat': base_location['lat'],\n",
        "            'lon': base_location['lon'],\n",
        "            'rmse': base_metrics['test_rmse'],\n",
        "            'r2': base_metrics['test_r2'],\n",
        "            'training_type': 'base'\n",
        "        })\n",
        "\n",
        "        # Test on other locations\n",
        "        for location in locations_list[1:]:\n",
        "            print(f\"Testing on {location['name']} data...\")\n",
        "\n",
        "            test_analyzer = ComprehensiveSolarForecaster(location['data_path'])\n",
        "            test_analyzer.load_and_preprocess()\n",
        "            test_analyzer.prepare_features()\n",
        "\n",
        "            X = test_analyzer.df[test_analyzer.features].fillna(0)\n",
        "            y = test_analyzer.df[test_analyzer.target]\n",
        "\n",
        "            X_scaled = self.scaler.transform(X)\n",
        "            y_pred = base_model.predict(X_scaled)\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "            r2 = r2_score(y, y_pred)\n",
        "\n",
        "            results.append({\n",
        "                'location': location['name'],\n",
        "                'lat': location['lat'],\n",
        "                'lon': location['lon'],\n",
        "                'rmse': rmse,\n",
        "                'r2': r2,\n",
        "                'training_type': 'transfer'\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        self._plot_geographic_transferability(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def analyze_temporal_resolution(self, resolutions=None):\n",
        "        \"\"\"Fixed temporal resolution analysis\"\"\"\n",
        "\n",
        "        if resolutions is None:\n",
        "            resolutions = [\n",
        "                {'name': '30min', 'freq': '30min'},\n",
        "                {'name': 'hourly', 'freq': 'H'},\n",
        "                {'name': 'daily', 'freq': 'D'},\n",
        "                {'name': 'weekly', 'freq': 'W'}\n",
        "            ]\n",
        "\n",
        "        results = []\n",
        "        original_df = self.df.copy()\n",
        "\n",
        "        for resolution in resolutions:\n",
        "            print(f\"Analyzing {resolution['name']} resolution...\")\n",
        "\n",
        "            if resolution['freq'] == 'H':\n",
        "                self.df = original_df.copy()\n",
        "            elif resolution['freq'] == '30min':\n",
        "                self.df = self._interpolate_to_30min_fixed(original_df)\n",
        "            else:\n",
        "                self.df = self._resample_data(original_df, resolution['freq'])\n",
        "\n",
        "            self.prepare_features()\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data_temporal()\n",
        "\n",
        "            model = self._build_random_forest(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            metrics = self.models['random_forest']['metrics']\n",
        "\n",
        "            results.append({\n",
        "                'resolution': resolution['name'],\n",
        "                'freq': resolution['freq'],\n",
        "                'test_rmse': metrics['test_rmse'],\n",
        "                'test_r2': metrics['test_r2'],\n",
        "                'sample_count': len(self.df)\n",
        "            })\n",
        "\n",
        "        self.df = original_df\n",
        "        results_df = pd.DataFrame(results)\n",
        "        self._plot_temporal_resolution_performance(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _interpolate_to_30min_fixed(self, df):\n",
        "        \"\"\"Fixed version: Convert hourly data to 30-minute resolution\"\"\"\n",
        "        start_date = df['datetime'].min()\n",
        "        end_date = df['datetime'].max()\n",
        "        new_index = pd.date_range(start=start_date, end=end_date, freq='30min')\n",
        "\n",
        "        df_30min = pd.DataFrame(index=new_index)\n",
        "        df_30min.index.name = 'datetime'\n",
        "\n",
        "        df_hourly = df.set_index('datetime')\n",
        "\n",
        "        # Separate numeric and non-numeric columns\n",
        "        numeric_cols = df_hourly.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        # Only interpolate numeric columns\n",
        "        df_numeric = df_hourly[numeric_cols]\n",
        "        df_combined = df_30min.join(df_numeric, how='left')\n",
        "        df_combined = df_combined.interpolate(method='time')\n",
        "        df_combined = df_combined.reset_index()\n",
        "\n",
        "        # Recreate all temporal features using the new datetime index\n",
        "        self._recreate_temporal_features_for_resampled(df_combined)\n",
        "\n",
        "        return df_combined\n",
        "\n",
        "    def _resample_data(self, df, freq):\n",
        "        \"\"\"Resample data to different frequency\"\"\"\n",
        "        df_temp = df.copy().set_index('datetime')\n",
        "\n",
        "        # Only resample numeric columns\n",
        "        numeric_cols = df_temp.select_dtypes(include=[np.number]).columns\n",
        "        resampled = df_temp[numeric_cols].resample(freq).mean()\n",
        "        resampled = resampled.reset_index()\n",
        "\n",
        "        # Recreate temporal features\n",
        "        self._recreate_temporal_features_for_resampled(resampled)\n",
        "\n",
        "        return resampled\n",
        "\n",
        "    def _recreate_temporal_features_for_resampled(self, df):\n",
        "        \"\"\"Recreate temporal features for resampled data\"\"\"\n",
        "        # Basic temporal features\n",
        "        df['hour'] = df['datetime'].dt.hour + df['datetime'].dt.minute/60  # Handle sub-hourly data\n",
        "        df['day'] = df['datetime'].dt.day\n",
        "        df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        df['year'] = df['datetime'].dt.year\n",
        "        df['day_of_year'] = df['datetime'].dt.dayofyear\n",
        "\n",
        "        # Cyclical encoding\n",
        "        df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
        "        df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
        "        df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "        df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "        df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year']/365)\n",
        "        df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year']/365)\n",
        "        df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week']/7)\n",
        "        df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week']/7)\n",
        "\n",
        "        # Season features\n",
        "        df['season_numeric'] = ((df['month'] % 12) // 3)\n",
        "        df['is_spring'] = (df['month'].isin([3, 4, 5])).astype(int)\n",
        "        df['is_summer'] = (df['month'].isin([6, 7, 8])).astype(int)\n",
        "        df['is_fall'] = (df['month'].isin([9, 10, 11])).astype(int)\n",
        "\n",
        "        # Binary indicators\n",
        "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "        df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def analyze_climate_zones(self, climate_data_paths):\n",
        "        results = []\n",
        "\n",
        "        # Train base model\n",
        "        self.prepare_features()\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data_temporal()\n",
        "        base_model = self._build_random_forest(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "        for climate_zone, data_path in climate_data_paths.items():\n",
        "            print(f\"Analyzing {climate_zone} climate zone...\")\n",
        "\n",
        "            zone_analyzer = ComprehensiveSolarForecaster(data_path)\n",
        "            zone_analyzer.load_and_preprocess()\n",
        "            zone_analyzer.prepare_features()\n",
        "\n",
        "            X_zone_train, X_zone_val, X_zone_test, y_zone_train, y_zone_val, y_zone_test = zone_analyzer.split_data_temporal()\n",
        "\n",
        "            # Train zone-specific model\n",
        "            zone_model = zone_analyzer._build_random_forest(X_zone_train, y_zone_train, X_zone_val, y_zone_val, X_zone_test, y_zone_test)\n",
        "            zone_metrics = zone_analyzer.models['random_forest']['metrics']\n",
        "\n",
        "            # Test base model on zone data\n",
        "            base_pred = base_model.predict(X_zone_test)\n",
        "            base_rmse = np.sqrt(mean_squared_error(y_zone_test, base_pred))\n",
        "            base_r2 = r2_score(y_zone_test, base_pred)\n",
        "\n",
        "            results.append({\n",
        "                'climate_zone': climate_zone,\n",
        "                'zone_specific_rmse': zone_metrics['test_rmse'],\n",
        "                'zone_specific_r2': zone_metrics['test_r2'],\n",
        "                'base_model_rmse': base_rmse,\n",
        "                'base_model_r2': base_r2,\n",
        "                'performance_gap_rmse': base_rmse - zone_metrics['test_rmse'],\n",
        "                'performance_gap_r2': zone_metrics['test_r2'] - base_r2\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        self._plot_climate_zone_performance(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def incorporate_weather_parameters(self, weather_data_path):\n",
        "        # Load weather data\n",
        "        weather_df = pd.read_csv(weather_data_path)\n",
        "        weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n",
        "\n",
        "        # Merge with solar data\n",
        "        merged_df = pd.merge(self.df, weather_df, on='datetime', how='inner')\n",
        "        original_df = self.df.copy()\n",
        "        self.df = merged_df\n",
        "\n",
        "        # Train baseline model (without weather)\n",
        "        self.prepare_features(include_weather=False)\n",
        "        X_train_base, X_val_base, X_test_base, y_train_base, y_val_base, y_test_base = self.split_data_temporal()\n",
        "        base_model = self._build_random_forest(X_train_base, y_train_base, X_val_base, y_val_base, X_test_base, y_test_base)\n",
        "        base_metrics = self.models['random_forest']['metrics']\n",
        "\n",
        "        # Train enhanced model (with weather)\n",
        "        self.prepare_features(include_weather=True)\n",
        "        X_train_enh, X_val_enh, X_test_enh, y_train_enh, y_val_enh, y_test_enh = self.split_data_temporal()\n",
        "        enhanced_model = self._build_random_forest(X_train_enh, y_train_enh, X_val_enh, y_val_enh, X_test_enh, y_test_enh)\n",
        "        enhanced_metrics = self.models['random_forest']['metrics']\n",
        "\n",
        "        # Compare performance\n",
        "        comparison = {\n",
        "            'baseline': base_metrics,\n",
        "            'enhanced': enhanced_metrics,\n",
        "            'improvement': {\n",
        "                'rmse': base_metrics['test_rmse'] - enhanced_metrics['test_rmse'],\n",
        "                'rmse_percent': (base_metrics['test_rmse'] - enhanced_metrics['test_rmse']) / base_metrics['test_rmse'] * 100,\n",
        "                'r2': enhanced_metrics['test_r2'] - base_metrics['test_r2']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"\\nPerformance Comparison:\")\n",
        "        print(f\"Baseline RMSE: {base_metrics['test_rmse']:.4f}\")\n",
        "        print(f\"Enhanced RMSE: {enhanced_metrics['test_rmse']:.4f}\")\n",
        "        print(f\"Improvement: {comparison['improvement']['rmse']:.4f} ({comparison['improvement']['rmse_percent']:.2f}%)\")\n",
        "        print(f\"Baseline R²: {base_metrics['test_r2']:.4f}\")\n",
        "        print(f\"Enhanced R²: {enhanced_metrics['test_r2']:.4f}\")\n",
        "        print(f\"R² Improvement: {comparison['improvement']['r2']:.4f}\")\n",
        "\n",
        "        self.df = original_df\n",
        "        self._plot_weather_impact_comparison(comparison)\n",
        "\n",
        "        return comparison\n",
        "\n",
        "    def _plot_model_comparison(self, results_df):\n",
        "        \"\"\"Plot model comparison results\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        # RMSE comparison\n",
        "        axes[0, 0].bar(results_df['model'], results_df['test_rmse'], color='lightcoral')\n",
        "        axes[0, 0].set_title('Test RMSE Comparison')\n",
        "        axes[0, 0].set_ylabel('RMSE')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # R² comparison\n",
        "        axes[0, 1].bar(results_df['model'], results_df['test_r2'], color='lightblue')\n",
        "        axes[0, 1].set_title('Test R² Comparison')\n",
        "        axes[0, 1].set_ylabel('R² Score')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # MAE comparison\n",
        "        axes[1, 0].bar(results_df['model'], results_df['test_mae'], color='lightgreen')\n",
        "        axes[1, 0].set_title('Test MAE Comparison')\n",
        "        axes[1, 0].set_ylabel('MAE')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Training time\n",
        "        axes[1, 1].bar(results_df['model'], results_df['training_time'], color='gold')\n",
        "        axes[1, 1].set_title('Training Time Comparison')\n",
        "        axes[1, 1].set_ylabel('Time (seconds)')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/comparisons/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_geographic_transferability(self, results_df):\n",
        "        \"\"\"Plot geographic transferability results\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # RMSE by location\n",
        "        sns.scatterplot(data=results_df, x='lon', y='lat', size='rmse',\n",
        "                       hue='training_type', ax=axes[0])\n",
        "        axes[0].set_title('Geographic Performance - RMSE')\n",
        "        axes[0].set_xlabel('Longitude')\n",
        "        axes[0].set_ylabel('Latitude')\n",
        "\n",
        "        # R² by location\n",
        "        sns.scatterplot(data=results_df, x='lon', y='lat', size='r2',\n",
        "                       hue='training_type', ax=axes[1])\n",
        "        axes[1].set_title('Geographic Performance - R²')\n",
        "        axes[1].set_xlabel('Longitude')\n",
        "        axes[1].set_ylabel('Latitude')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/comparisons/geographic_transferability.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_temporal_resolution_performance(self, results_df):\n",
        "        \"\"\"Plot temporal resolution performance\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        axes[0].plot(results_df['resolution'], results_df['test_rmse'], 'o-', linewidth=2, markersize=8)\n",
        "        axes[0].set_title('RMSE vs Temporal Resolution')\n",
        "        axes[0].set_ylabel('Test RMSE')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        axes[1].plot(results_df['resolution'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='green')\n",
        "        axes[1].set_title('R² vs Temporal Resolution')\n",
        "        axes[1].set_ylabel('Test R²')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/comparisons/temporal_resolution.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_climate_zone_performance(self, results_df):\n",
        "        \"\"\"Plot climate zone performance\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Zone-specific vs base model RMSE\n",
        "        x = np.arange(len(results_df))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[0, 0].bar(x - width/2, results_df['zone_specific_rmse'], width, label='Zone-specific', alpha=0.8)\n",
        "        axes[0, 0].bar(x + width/2, results_df['base_model_rmse'], width, label='Base model', alpha=0.8)\n",
        "        axes[0, 0].set_title('RMSE Comparison by Climate Zone')\n",
        "        axes[0, 0].set_ylabel('RMSE')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels(results_df['climate_zone'], rotation=45)\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        # R² comparison\n",
        "        axes[0, 1].bar(x - width/2, results_df['zone_specific_r2'], width, label='Zone-specific', alpha=0.8)\n",
        "        axes[0, 1].bar(x + width/2, results_df['base_model_r2'], width, label='Base model', alpha=0.8)\n",
        "        axes[0, 1].set_title('R² Comparison by Climate Zone')\n",
        "        axes[0, 1].set_ylabel('R² Score')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels(results_df['climate_zone'], rotation=45)\n",
        "        axes[0, 1].legend()\n",
        "\n",
        "        # Performance gaps\n",
        "        axes[1, 0].bar(results_df['climate_zone'], results_df['performance_gap_rmse'])\n",
        "        axes[1, 0].set_title('RMSE Performance Gap')\n",
        "        axes[1, 0].set_ylabel('Gap (Base - Zone-specific)')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        axes[1, 1].bar(results_df['climate_zone'], results_df['performance_gap_r2'])\n",
        "        axes[1, 1].set_title('R² Performance Gap')\n",
        "        axes[1, 1].set_ylabel('Gap (Zone-specific - Base)')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/comparisons/climate_zones.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_weather_impact_comparison(self, comparison):\n",
        "        \"\"\"Plot weather parameter impact\"\"\"\n",
        "        metrics = ['test_rmse', 'test_r2', 'test_mae']\n",
        "        baseline_values = [comparison['baseline'][m] for m in metrics]\n",
        "        enhanced_values = [comparison['enhanced'][m] for m in metrics]\n",
        "\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.35\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.bar(x - width/2, baseline_values, width, label='Baseline', alpha=0.8)\n",
        "        ax.bar(x + width/2, enhanced_values, width, label='With Weather', alpha=0.8)\n",
        "\n",
        "        ax.set_title('Impact of Weather Parameters on Model Performance')\n",
        "        ax.set_ylabel('Metric Value')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(['RMSE', 'R²', 'MAE'])\n",
        "        ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/comparisons/weather_impact.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _generate_model_comparison_report(self, results_df):\n",
        "        \"\"\"Generate comprehensive model comparison report\"\"\"\n",
        "        report_content = []\n",
        "\n",
        "        report_content.extend([\n",
        "            \"=\"*80,\n",
        "            \"COMPREHENSIVE MODEL COMPARISON REPORT\",\n",
        "            \"=\"*80,\n",
        "            f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            \"\"\n",
        "        ])\n",
        "\n",
        "        # Best performing model\n",
        "        best_r2_model = results_df.loc[results_df['test_r2'].idxmax()]\n",
        "        best_rmse_model = results_df.loc[results_df['test_rmse'].idxmin()]\n",
        "\n",
        "        report_content.extend([\n",
        "            \"PERFORMANCE RANKING\",\n",
        "            \"-\"*40,\n",
        "            f\"Best R² Score: {best_r2_model['model']} ({best_r2_model['test_r2']:.4f})\",\n",
        "            f\"Best RMSE: {best_rmse_model['model']} ({best_rmse_model['test_rmse']:.4f})\",\n",
        "            \"\"\n",
        "        ])\n",
        "\n",
        "        # Detailed comparison\n",
        "        report_content.extend([\n",
        "            \"DETAILED COMPARISON\",\n",
        "            \"-\"*40\n",
        "        ])\n",
        "\n",
        "        for _, row in results_df.iterrows():\n",
        "            report_content.extend([\n",
        "                f\"{row['model'].upper()}:\",\n",
        "                f\"  RMSE: {row['test_rmse']:.4f}\",\n",
        "                f\"  R²: {row['test_r2']:.4f}\",\n",
        "                f\"  MAE: {row['test_mae']:.4f}\",\n",
        "                f\"  Training Time: {row['training_time']:.2f}s\",\n",
        "                \"\"\n",
        "            ])\n",
        "\n",
        "        # Save report\n",
        "        with open('solar_analysis_results/comparisons/model_comparison_report.txt', 'w') as f:\n",
        "            f.write('\\n'.join(report_content))\n",
        "\n",
        "        print('\\n'.join(report_content))\n",
        "\n",
        "    def generate_comprehensive_report(self):\n",
        "        print(\"\\nGenerating comprehensive framework report...\")\n",
        "\n",
        "        report_content = [\n",
        "            \"COMPREHENSIVE SOLAR FORECASTING FRAMEWORK REPORT\",\n",
        "            \"=\"*80,\n",
        "            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "        ]\n",
        "\n",
        "        with open('solar_analysis_results/comprehensive_framework_report.txt', 'w') as f:\n",
        "            f.write('\\n'.join(report_content))\n",
        "\n",
        "        print('\\n'.join(report_content))\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"COMPREHENSIVE SOLAR FORECASTING FRAMEWORK\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Initialize framework\n",
        "    data_path = 'solar_data.csv'  # Update path as needed\n",
        "    forecaster = ComprehensiveSolarForecaster(data_path)\n",
        "\n",
        "    try:\n",
        "        print(\"\\nSTEP 1: DATA LOADING AND PREPROCESSING\")\n",
        "        forecaster.load_and_preprocess()\n",
        "\n",
        "        print(\"\\nSTEP 2: COMPREHENSIVE MODEL COMPARISON\")\n",
        "        model_results = forecaster.compare_models()\n",
        "\n",
        "        # Step 3: Test geographic transferability (example)\n",
        "        # locations = [\n",
        "        #     {'name': 'New Delhi', 'lat': 28.6, 'lon': 77.2, 'data_path': 'delhi_data.csv'},\n",
        "        #     {'name': 'Mumbai', 'lat': 19.1, 'lon': 72.9, 'data_path': 'mumbai_data.csv'},\n",
        "        # ]\n",
        "\n",
        "        print(\"\\nSTEP 4: TEMPORAL RESOLUTION ANALYSIS\")\n",
        "        temporal_results = forecaster.analyze_temporal_resolution()\n",
        "\n",
        "        print(\"\\nSTEP 6: COMPREHENSIVE REPORT GENERATION\")\n",
        "        forecaster.generate_comprehensive_report()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FRAMEWORK ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Results saved in 'solar_analysis_results/' directory\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"Please check your data files and paths.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}