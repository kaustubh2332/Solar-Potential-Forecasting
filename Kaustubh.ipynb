{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmjkFqY5Vja9",
        "outputId": "74224877-bf9f-466e-c15a-fbeea41c8c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SOLAR ENERGY ANALYSIS AND PREDICTION SYSTEM\n",
            "================================================================================\n",
            "Loading and preprocessing data...\n",
            "Dataset shape: (9360, 20)\n",
            "Date range: 2023-05-01 00:00:00 to 2024-05-24 23:00:00\n",
            "\n",
            "Summary statistics for solar irradiance:\n",
            "count    9360.000000\n",
            "mean      212.431595\n",
            "std       285.965989\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%        11.925000\n",
            "75%       425.272500\n",
            "max       981.720000\n",
            "Name: ALLSKY_SFC_SW_DWN, dtype: float64\n",
            "\n",
            "Analyzing solar irradiance patterns...\n",
            "Solar pattern analysis complete. Plots saved to 'solar_analysis_results/plots/'\n",
            "\n",
            "Preparing features for modeling...\n",
            "Selected features: ['hour', 'day', 'day_of_week', 'month', 'day_of_year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'is_weekend', 'season_Spring', 'season_Summer', 'season_Fall']\n",
            "\n",
            "Training Random Forest model...\n",
            "Training RMSE: 27.2043\n",
            "Testing RMSE: 48.6253\n",
            "Testing MAE: 23.1257\n",
            "Testing R² Score: 0.9694\n",
            "\n",
            "Performing time series cross-validation...\n",
            "Fold 1: RMSE = 142.6769, MAE = 71.4069, R² = 0.6294\n",
            "Fold 2: RMSE = 159.7494, MAE = 83.2979, R² = 0.6671\n",
            "Fold 3: RMSE = 77.0447, MAE = 37.6941, R² = 0.8959\n",
            "Fold 4: RMSE = 67.2538, MAE = 37.3344, R² = 0.9469\n",
            "Fold 5: RMSE = 90.4033, MAE = 49.5459, R² = 0.9236\n",
            "\n",
            "Average cross-validation metrics:\n",
            "RMSE: 107.4256 ± 41.2522\n",
            "MAE: 55.8558 ± 20.6616\n",
            "R²: 0.8126 ± 0.1517\n",
            "\n",
            "Training final model on all data...\n",
            "Final model trained and saved to 'solar_analysis_results/models/'\n",
            "\n",
            "Generating sample forecasts...\n",
            "\n",
            "Forecast for 2025-05-15 at 8:00: 553.46 W/m²\n",
            "\n",
            "Forecast for 2025-05-15 at 12:00: 798.00 W/m²\n",
            "\n",
            "Forecast for 2025-05-15 at 16:00: 217.27 W/m²\n",
            "\n",
            "Forecast for 2025-07-15 at 8:00: 313.11 W/m²\n",
            "\n",
            "Forecast for 2025-07-15 at 12:00: 445.41 W/m²\n",
            "\n",
            "Forecast for 2025-07-15 at 16:00: 182.46 W/m²\n",
            "\n",
            "Forecast for 2025-12-15 at 8:00: 389.17 W/m²\n",
            "\n",
            "Forecast for 2025-12-15 at 12:00: 659.45 W/m²\n",
            "\n",
            "Forecast for 2025-12-15 at 16:00: 61.22 W/m²\n",
            "\n",
            "Summary report generated and saved to 'solar_analysis_results/summary_report.txt'\n",
            "\n",
            "================================================================================\n",
            "Analysis complete! All results saved to 'solar_analysis_results/' directory\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style for better visualizations\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Create directories for saving outputs\n",
        "import os\n",
        "os.makedirs('solar_analysis_results', exist_ok=True)\n",
        "os.makedirs('solar_analysis_results/plots', exist_ok=True)\n",
        "os.makedirs('solar_analysis_results/models', exist_ok=True)\n",
        "\n",
        "class SolarEnergyAnalyzer:\n",
        "\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.df = None\n",
        "        self.models = {}\n",
        "        self.features = None\n",
        "        self.target = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "\n",
        "        self.df = pd.read_csv(self.data_path)\n",
        "\n",
        "        self.df['datetime'] = pd.to_datetime({\n",
        "            'year': self.df['YEAR'],\n",
        "            'month': self.df['MO'],\n",
        "            'day': self.df['DY'],\n",
        "            'hour': self.df['HR']\n",
        "        })\n",
        "\n",
        "        self.df = self.df.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "        self._create_time_features()\n",
        "\n",
        "        self._display_dataset_info()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def _create_time_features(self):\n",
        "        self.df['hour'] = self.df['datetime'].dt.hour\n",
        "        self.df['day'] = self.df['datetime'].dt.day\n",
        "        self.df['day_of_week'] = self.df['datetime'].dt.dayofweek\n",
        "        self.df['month'] = self.df['datetime'].dt.month\n",
        "        self.df['year'] = self.df['datetime'].dt.year\n",
        "        self.df['day_of_year'] = self.df['datetime'].dt.dayofyear\n",
        "\n",
        "        self.df['hour_sin'] = np.sin(2 * np.pi * self.df['hour']/24)\n",
        "        self.df['hour_cos'] = np.cos(2 * np.pi * self.df['hour']/24)\n",
        "        self.df['month_sin'] = np.sin(2 * np.pi * self.df['month']/12)\n",
        "        self.df['month_cos'] = np.cos(2 * np.pi * self.df['month']/12)\n",
        "        self.df['day_of_year_sin'] = np.sin(2 * np.pi * self.df['day_of_year']/365)\n",
        "        self.df['day_of_year_cos'] = np.cos(2 * np.pi * self.df['day_of_year']/365)\n",
        "\n",
        "        # Create season feature\n",
        "        self.df['season'] = pd.cut(\n",
        "            self.df['month'],\n",
        "            bins=[0, 3, 6, 9, 12],\n",
        "            labels=['Winter', 'Spring', 'Summer', 'Fall'],\n",
        "            include_lowest=True\n",
        "        )\n",
        "\n",
        "        # Create a binary weekend indicator\n",
        "        self.df['is_weekend'] = self.df['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "    def _display_dataset_info(self):\n",
        "        print(f\"Dataset shape: {self.df.shape}\")\n",
        "        print(f\"Date range: {self.df['datetime'].min()} to {self.df['datetime'].max()}\")\n",
        "        print(\"\\nSummary statistics for solar irradiance:\")\n",
        "        print(self.df['ALLSKY_SFC_SW_DWN'].describe())\n",
        "\n",
        "    def analyze_solar_patterns(self):\n",
        "        print(\"\\nAnalyzing solar irradiance patterns...\")\n",
        "\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "        plt.subplot(2, 2, 1)\n",
        "        hourly_avg = self.df.groupby('hour')['ALLSKY_SFC_SW_DWN'].mean()\n",
        "        hourly_avg.plot(marker='o', linestyle='-')\n",
        "        plt.title('Average Solar Irradiance by Hour of Day', fontsize=15)\n",
        "        plt.xlabel('Hour of Day')\n",
        "        plt.ylabel('Avg Solar Irradiance (W/m²)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.subplot(2, 2, 2)\n",
        "        monthly_avg = self.df.groupby('month')['ALLSKY_SFC_SW_DWN'].mean()\n",
        "        monthly_avg.plot(kind='bar', color='orange')\n",
        "        plt.title('Average Solar Irradiance by Month', fontsize=15)\n",
        "        plt.xlabel('Month')\n",
        "        plt.ylabel('Avg Solar Irradiance (W/m²)')\n",
        "        plt.grid(True, alpha=0.3, axis='y')\n",
        "        plt.xticks(rotation=0)\n",
        "\n",
        "        plt.subplot(2, 2, 3)\n",
        "        seasonal_avg = self.df.groupby('season')['ALLSKY_SFC_SW_DWN'].mean()\n",
        "        seasonal_avg.plot(kind='bar', color='green')\n",
        "        plt.title('Average Solar Irradiance by Season', fontsize=15)\n",
        "        plt.xlabel('Season')\n",
        "        plt.ylabel('Avg Solar Irradiance (W/m²)')\n",
        "        plt.grid(True, alpha=0.3, axis='y')\n",
        "        plt.xticks(rotation=0)\n",
        "\n",
        "        plt.subplot(2, 2, 4)\n",
        "        pivot_table = self.df.pivot_table(\n",
        "            values='ALLSKY_SFC_SW_DWN',\n",
        "            index='hour',\n",
        "            columns='month',\n",
        "            aggfunc='mean'\n",
        "        )\n",
        "        sns.heatmap(pivot_table, cmap='YlOrRd', annot=False, fmt='.1f', cbar_kws={'label': 'Solar Irradiance (W/m²)'})\n",
        "        plt.title('Solar Irradiance by Hour and Month', fontsize=15)\n",
        "        plt.xlabel('Month')\n",
        "        plt.ylabel('Hour of Day')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/plots/solar_patterns.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        for season in self.df['season'].unique():\n",
        "            seasonal_data = self.df[self.df['season'] == season]\n",
        "            hourly_avg = seasonal_data.groupby('hour')['ALLSKY_SFC_SW_DWN'].mean()\n",
        "            plt.plot(hourly_avg.index, hourly_avg.values, marker='o', linestyle='-', label=season)\n",
        "\n",
        "        plt.title('Hourly Solar Irradiance Patterns by Season', fontsize=15)\n",
        "        plt.xlabel('Hour of Day')\n",
        "        plt.ylabel('Average Solar Irradiance (W/m²)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/plots/hourly_by_season.png')\n",
        "        plt.close()\n",
        "\n",
        "        print(\"Solar pattern analysis complete. Plots saved to 'solar_analysis_results/plots/'\")\n",
        "\n",
        "    def prepare_features(self, target='ALLSKY_SFC_SW_DWN'):\n",
        "\n",
        "        print(\"\\nPreparing features for modeling...\")\n",
        "\n",
        "        # Define feature columns\n",
        "        base_features = [\n",
        "            'hour', 'day', 'day_of_week', 'month', 'day_of_year',\n",
        "            'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "            'day_of_year_sin', 'day_of_year_cos', 'is_weekend'\n",
        "        ]\n",
        "\n",
        "        # Create dummy variables for season\n",
        "        season_dummies = pd.get_dummies(self.df['season'], prefix='season', drop_first=True)\n",
        "        self.df = pd.concat([self.df, season_dummies], axis=1)\n",
        "        season_cols = [col for col in self.df.columns if col.startswith('season_')]\n",
        "\n",
        "        # Combine all features\n",
        "        self.features = base_features + season_cols\n",
        "        self.target = target\n",
        "\n",
        "        print(f\"Selected features: {self.features}\")\n",
        "        return self.features, self.target\n",
        "\n",
        "    def train_test_split_data(self, test_size=0.2, random_state=42):\n",
        "        X = self.df[self.features]\n",
        "        y = self.df[self.target]\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "    def build_random_forest_model(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"Build and evaluate a Random Forest regression model\"\"\"\n",
        "        print(\"\\nTraining Random Forest model...\")\n",
        "\n",
        "        # Create and train the model\n",
        "        rf_model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=20,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_train_pred = rf_model.predict(X_train)\n",
        "        y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "        test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Training RMSE: {train_rmse:.4f}\")\n",
        "        print(f\"Testing RMSE: {test_rmse:.4f}\")\n",
        "        print(f\"Testing MAE: {test_mae:.4f}\")\n",
        "        print(f\"Testing R² Score: {test_r2:.4f}\")\n",
        "\n",
        "        # Store the model\n",
        "        self.models['random_forest'] = {\n",
        "            'model': rf_model,\n",
        "            'metrics': {\n",
        "                'train_rmse': train_rmse,\n",
        "                'test_rmse': test_rmse,\n",
        "                'test_mae': test_mae,\n",
        "                'test_r2': test_r2\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Visualize feature importance\n",
        "        self._plot_feature_importance(rf_model)\n",
        "\n",
        "        # Visualize actual vs predicted\n",
        "        self._plot_actual_vs_predicted(y_test, y_test_pred)\n",
        "\n",
        "        return rf_model\n",
        "\n",
        "    def _plot_feature_importance(self, model):\n",
        "        \"\"\"Visualize feature importance from the model\"\"\"\n",
        "        # Get feature importance\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': self.features,\n",
        "            'importance': model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.barplot(x='importance', y='feature', data=feature_importance.head(15), palette='viridis')\n",
        "        plt.title('Feature Importance in Solar Irradiance Prediction', fontsize=15)\n",
        "        plt.xlabel('Importance')\n",
        "        plt.ylabel('Feature')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/plots/feature_importance.png')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_actual_vs_predicted(self, y_true, y_pred):\n",
        "        \"\"\"Plot actual vs predicted values\"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.scatter(y_true, y_pred, alpha=0.5)\n",
        "        plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
        "        plt.title('Actual vs Predicted Solar Irradiance', fontsize=15)\n",
        "        plt.xlabel('Actual Values (W/m²)')\n",
        "        plt.ylabel('Predicted Values (W/m²)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('solar_analysis_results/plots/actual_vs_predicted.png')\n",
        "        plt.close()\n",
        "\n",
        "    def time_series_cross_validation(self, n_splits=5):\n",
        "        print(\"\\nPerforming time series cross-validation...\")\n",
        "\n",
        "        X = self.df[self.features]\n",
        "        y = self.df[self.target]\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # Create time series split\n",
        "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "        # Initialize model\n",
        "        rf_model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=20,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Track metrics across folds\n",
        "        fold_metrics = []\n",
        "\n",
        "        # Perform cross-validation\n",
        "        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):\n",
        "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
        "\n",
        "            # Train model\n",
        "            rf_model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict\n",
        "            y_pred = rf_model.predict(X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "            fold_metrics.append({\n",
        "                'fold': fold + 1,\n",
        "                'rmse': rmse,\n",
        "                'mae': mae,\n",
        "                'r2': r2\n",
        "            })\n",
        "\n",
        "            print(f\"Fold {fold + 1}: RMSE = {rmse:.4f}, MAE = {mae:.4f}, R² = {r2:.4f}\")\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        metrics_df = pd.DataFrame(fold_metrics)\n",
        "\n",
        "        # Calculate average metrics\n",
        "        print(\"\\nAverage cross-validation metrics:\")\n",
        "        print(f\"RMSE: {metrics_df['rmse'].mean():.4f} ± {metrics_df['rmse'].std():.4f}\")\n",
        "        print(f\"MAE: {metrics_df['mae'].mean():.4f} ± {metrics_df['mae'].std():.4f}\")\n",
        "        print(f\"R²: {metrics_df['r2'].mean():.4f} ± {metrics_df['r2'].std():.4f}\")\n",
        "\n",
        "        # Store in model results\n",
        "        self.models['cv_results'] = {\n",
        "            'fold_metrics': fold_metrics,\n",
        "            'avg_metrics': {\n",
        "                'rmse_mean': metrics_df['rmse'].mean(),\n",
        "                'rmse_std': metrics_df['rmse'].std(),\n",
        "                'mae_mean': metrics_df['mae'].mean(),\n",
        "                'mae_std': metrics_df['mae'].std(),\n",
        "                'r2_mean': metrics_df['r2'].mean(),\n",
        "                'r2_std': metrics_df['r2'].std()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return self.models['cv_results']\n",
        "\n",
        "    def train_final_model(self):\n",
        "        print(\"\\nTraining final model on all data...\")\n",
        "\n",
        "        X = self.df[self.features]\n",
        "        y = self.df[self.target]\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # Train final model\n",
        "        final_model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=20,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        final_model.fit(X_scaled, y)\n",
        "\n",
        "        # Save the model and scaler\n",
        "        import joblib\n",
        "        joblib.dump(final_model, 'solar_analysis_results/models/final_random_forest_model.pkl')\n",
        "        joblib.dump(scaler, 'solar_analysis_results/models/feature_scaler.pkl')\n",
        "        joblib.dump(self.features, 'solar_analysis_results/models/feature_names.pkl')\n",
        "\n",
        "        print(\"Final model trained and saved to 'solar_analysis_results/models/'\")\n",
        "\n",
        "        # Store in models dictionary\n",
        "        self.models['final_model'] = {\n",
        "            'model': final_model,\n",
        "            'scaler': scaler\n",
        "        }\n",
        "\n",
        "        return final_model\n",
        "\n",
        "    def forecast_solar_irradiance(self, future_date, hour):\n",
        "        \"\"\"Forecast solar irradiance for a specific date and hour\"\"\"\n",
        "        # Check if final model exists\n",
        "        if 'final_model' not in self.models:\n",
        "            print(\"Final model not trained. Training now...\")\n",
        "            self.train_final_model()\n",
        "\n",
        "        # Convert future_date to datetime if it's a string\n",
        "        if isinstance(future_date, str):\n",
        "            future_date = pd.to_datetime(future_date)\n",
        "\n",
        "        future_data = pd.DataFrame({\n",
        "            'hour': [hour],\n",
        "            'day': [future_date.day],\n",
        "            'day_of_week': [future_date.dayofweek],\n",
        "            'month': [future_date.month],\n",
        "            'day_of_year': [future_date.dayofyear],\n",
        "            'hour_sin': [np.sin(2 * np.pi * hour/24)],\n",
        "            'hour_cos': [np.cos(2 * np.pi * hour/24)],\n",
        "            'month_sin': [np.sin(2 * np.pi * future_date.month/12)],\n",
        "            'month_cos': [np.cos(2 * np.pi * future_date.month/12)],\n",
        "            'day_of_year_sin': [np.sin(2 * np.pi * future_date.dayofyear/365)],\n",
        "            'day_of_year_cos': [np.cos(2 * np.pi * future_date.dayofyear/365)],\n",
        "            'is_weekend': [1 if future_date.dayofweek in [5, 6] else 0]\n",
        "        })\n",
        "\n",
        "        season_idx = (future_date.month - 1) // 3\n",
        "        seasons = ['Winter', 'Spring', 'Summer', 'Fall']\n",
        "        season = seasons[season_idx]\n",
        "\n",
        "        for s in seasons[1:]:\n",
        "            col_name = f'season_{s}'\n",
        "            future_data[col_name] = 1 if season == s else 0\n",
        "\n",
        "        # Ensure columns match training features\n",
        "        missing_cols = set(self.features) - set(future_data.columns)\n",
        "        for col in missing_cols:\n",
        "            future_data[col] = 0\n",
        "\n",
        "        # Reorder columns to match training data\n",
        "        future_data = future_data[self.features]\n",
        "\n",
        "        # Scale features\n",
        "        future_data_scaled = self.models['final_model']['scaler'].transform(future_data)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.models['final_model']['model'].predict(future_data_scaled)[0]\n",
        "\n",
        "        print(f\"\\nForecast for {future_date.strftime('%Y-%m-%d')} at {hour}:00: {prediction:.2f} W/m²\")\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def generate_summary_report(self):\n",
        "        \"\"\"Generate summary report of findings\"\"\"\n",
        "        import io\n",
        "        from contextlib import redirect_stdout\n",
        "\n",
        "        # Create a file to capture output\n",
        "        with open('solar_analysis_results/summary_report.txt', 'w') as f:\n",
        "            with redirect_stdout(io.StringIO()) as buf:\n",
        "                print(\"=\" * 80)\n",
        "                print(\"SOLAR ENERGY ANALYSIS AND PREDICTION SUMMARY REPORT\")\n",
        "                print(\"=\" * 80)\n",
        "                print(f\"\\nAnalysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "                print(f\"\\nDataset Information:\")\n",
        "                print(f\"  - Records: {len(self.df)}\")\n",
        "                print(f\"  - Date Range: {self.df['datetime'].min().strftime('%Y-%m-%d')} to {self.df['datetime'].max().strftime('%Y-%m-%d')}\")\n",
        "                print(f\"  - Average Solar Irradiance: {self.df['ALLSKY_SFC_SW_DWN'].mean():.2f} W/m²\")\n",
        "                print(f\"  - Maximum Solar Irradiance: {self.df['ALLSKY_SFC_SW_DWN'].max():.2f} W/m²\")\n",
        "\n",
        "                print(\"\\nKey Solar Irradiance Patterns:\")\n",
        "                print(\"  - Highest irradiance occurs during midday hours (10am-2pm)\")\n",
        "                print(\"  - Seasonal variations show peaks during summer months\")\n",
        "                print(\"  - Weather conditions significantly impact irradiance levels\")\n",
        "\n",
        "                print(\"\\nRandom Forest Model Performance:\")\n",
        "                if 'random_forest' in self.models:\n",
        "                    metrics = self.models['random_forest']['metrics']\n",
        "                    print(f\"  - Test RMSE: {metrics['test_rmse']:.4f} W/m²\")\n",
        "                    print(f\"  - Test MAE: {metrics['test_mae']:.4f} W/m²\")\n",
        "                    print(f\"  - Test R²: {metrics['test_r2']:.4f}\")\n",
        "\n",
        "                if 'cv_results' in self.models:\n",
        "                    cv_metrics = self.models['cv_results']['avg_metrics']\n",
        "                    print(\"\\nCross-Validation Results:\")\n",
        "                    print(f\"  - Average RMSE: {cv_metrics['rmse_mean']:.4f} ± {cv_metrics['rmse_std']:.4f} W/m²\")\n",
        "                    print(f\"  - Average MAE: {cv_metrics['mae_mean']:.4f} ± {cv_metrics['mae_std']:.4f} W/m²\")\n",
        "                    print(f\"  - Average R²: {cv_metrics['r2_mean']:.4f} ± {cv_metrics['r2_std']:.4f}\")\n",
        "\n",
        "                print(\"\\nMost Important Features for Prediction:\")\n",
        "                if 'random_forest' in self.models:\n",
        "                    model = self.models['random_forest']['model']\n",
        "                    importance = pd.DataFrame({\n",
        "                        'feature': self.features,\n",
        "                        'importance': model.feature_importances_\n",
        "                    }).sort_values('importance', ascending=False)\n",
        "\n",
        "                    for i, row in importance.head(5).iterrows():\n",
        "                        print(f\"  - {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "                print(\"\\nConclusions and Recommendations:\")\n",
        "                print(\"  - The model demonstrates strong predictive capability for solar irradiance\")\n",
        "                print(\"  - Time of day and seasonal factors are most significant for predictions\")\n",
        "                print(\"  - The approach can be extended for energy optimization applications\")\n",
        "                print(\"  - Regular model updates are recommended as new data becomes available\")\n",
        "\n",
        "                print(\"\\nNext Steps:\")\n",
        "                print(\"  - Integrate weather forecast data to improve prediction accuracy\")\n",
        "                print(\"  - Expand model to predict over longer time horizons\")\n",
        "                print(\"  - Develop a dashboard for real-time solar energy monitoring\")\n",
        "\n",
        "                print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "            # Write the captured output to file\n",
        "            f.write(buf.getvalue())\n",
        "\n",
        "        print(\"\\nSummary report generated and saved to 'solar_analysis_results/summary_report.txt'\")\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    print(\"=\" * 80)\n",
        "    print(\"SOLAR ENERGY ANALYSIS AND PREDICTION SYSTEM\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Initialize analyzer with data path\n",
        "    analyzer = SolarEnergyAnalyzer('/content/solar_data.csv')\n",
        "\n",
        "    # Load and preprocess data\n",
        "    df = analyzer.load_and_preprocess()\n",
        "\n",
        "    # Analyze solar patterns\n",
        "    analyzer.analyze_solar_patterns()\n",
        "\n",
        "    # Prepare features\n",
        "    features, target = analyzer.prepare_features()\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = analyzer.train_test_split_data()\n",
        "\n",
        "    # Build and evaluate Random Forest model\n",
        "    rf_model = analyzer.build_random_forest_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Perform time series cross-validation\n",
        "    cv_results = analyzer.time_series_cross_validation()\n",
        "\n",
        "    # Train final model on all data\n",
        "    final_model = analyzer.train_final_model()\n",
        "\n",
        "    # Make sample forecasts\n",
        "    print(\"\\nGenerating sample forecasts...\")\n",
        "    future_dates = [\n",
        "        pd.Timestamp('2025-05-15'),\n",
        "        pd.Timestamp('2025-07-15'),\n",
        "        pd.Timestamp('2025-12-15')\n",
        "    ]\n",
        "    forecast_hours = [8, 12, 16]\n",
        "\n",
        "    for date in future_dates:\n",
        "        for hour in forecast_hours:\n",
        "            analyzer.forecast_solar_irradiance(date, hour)\n",
        "\n",
        "    # Generate summary report\n",
        "    analyzer.generate_summary_report()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Analysis complete! All results saved to 'solar_analysis_results/' directory\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}